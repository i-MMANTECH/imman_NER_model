{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from spacy.lang.yo import Yoruba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = '../input/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(ROOT_DIR + \"news.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193279, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-21 18:28:18</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>New York City-area airports halt air traffic a...</td>\n",
       "      <td>The FAA said air traffic was halted at New Yor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-03-21 17:59:00</td>\n",
       "      <td>Yahoo.com</td>\n",
       "      <td>Airline CEOs promise to eliminate dividends an...</td>\n",
       "      <td>CEOs from America’s largest publicly traded ai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2020-03-21 17:13:04</td>\n",
       "      <td>Wcvb.com</td>\n",
       "      <td>Market Basket joins list of grocery stores mod...</td>\n",
       "      <td>The modified schedule begins Monday for all Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-03-21 17:00:00</td>\n",
       "      <td>Oilprice.com</td>\n",
       "      <td>What Happens If Oil Prices Go Negative - OilPr...</td>\n",
       "      <td>The combination of the Saudi Arabia vs Russia ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2020-03-21 16:49:56</td>\n",
       "      <td>The Verge</td>\n",
       "      <td>Amazon to start paying US warehouse workers do...</td>\n",
       "      <td>Amazon will raise overtime pay for workers in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id            timestamp        source  \\\n",
       "0   1  2020-03-21 18:28:18          CNBC   \n",
       "1   2  2020-03-21 17:59:00     Yahoo.com   \n",
       "2   3  2020-03-21 17:13:04      Wcvb.com   \n",
       "3   4  2020-03-21 17:00:00  Oilprice.com   \n",
       "4   5  2020-03-21 16:49:56     The Verge   \n",
       "\n",
       "                                               title  \\\n",
       "0  New York City-area airports halt air traffic a...   \n",
       "1  Airline CEOs promise to eliminate dividends an...   \n",
       "2  Market Basket joins list of grocery stores mod...   \n",
       "3  What Happens If Oil Prices Go Negative - OilPr...   \n",
       "4  Amazon to start paying US warehouse workers do...   \n",
       "\n",
       "                                         description  \n",
       "0  The FAA said air traffic was halted at New Yor...  \n",
       "1  CEOs from America’s largest publicly traded ai...  \n",
       "2  The modified schedule begins Monday for all Ma...  \n",
       "3  The combination of the Saudi Arabia vs Russia ...  \n",
       "4  Amazon will raise overtime pay for workers in ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CNBC' 'Yahoo.com' 'Wcvb.com' 'Oilprice.com' 'The Verge'\n",
      " 'Mercurynews.com' 'Google News' 'CNN' 'Fool.com' 'CBS News' 'Nytimes.com'\n",
      " 'Richmond.com' 'Newser.com' 'Wgntv.com' 'Chicagotribune.com' 'Forbes.com'\n",
      " 'Vox.com' 'Thepointsguy.com' 'Bloomberg' 'Reuters']\n"
     ]
    }
   ],
   "source": [
    "sources = df[\"source\"].unique()\n",
    "print(sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition = df[\"source\"].isin([\"CNBC\"])\n",
    "\n",
    "content_df = df.loc[condition, :][\"title\"][:100]\n",
    "content_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     New York City-area airports halt air traffic a...\n",
       "21    Why long-term investors should never sell stoc...\n",
       "44    Planning in the time of coronavirus means thin...\n",
       "48    Financing programs for businesses hit by the c...\n",
       "51    Breaking down this sell-off, among the most ex...\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York City-area airports halt air traffic as coronavirus causes staffing issues - CNBC\n",
      "Why long-term investors should never sell stocks in a panic\n"
     ]
    }
   ],
   "source": [
    "for article in content_df[:2]:\n",
    "    print(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New New PROPN NNP compound Xxx True False\n",
      "York York PROPN NNP compound Xxxx True False\n",
      "City City PROPN NNP compound Xxxx True False\n",
      "- - PUNCT HYPH punct - False False\n",
      "area area NOUN NN compound xxxx True False\n",
      "airports airport NOUN NNS nsubj xxxx True False\n",
      "halt halt VERB VBP ROOT xxxx True False\n",
      "air air NOUN NN compound xxx True False\n",
      "traffic traffic NOUN NN dobj xxxx True False\n",
      "as as SCONJ IN mark xx True True\n",
      "coronavirus coronavirus NOUN NN nsubj xxxx True False\n",
      "causes cause VERB VBZ advcl xxxx True False\n",
      "staffing staffing NOUN NN compound xxxx True False\n",
      "issues issue NOUN NNS dobj xxxx True False\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "text = \"New York City-area airports halt air traffic as coronavirus causes staffing issues\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_, token.shape_, token.is_alpha, token.is_stop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_entities_and_processed_docs(data_frame):\n",
    "    named_entities = {}\n",
    "    processed_docs = []\n",
    "\n",
    "    for item in data_frame:\n",
    "        doc = nlp(item)\n",
    "        processed_docs.append(doc)\n",
    "\n",
    "        for ent in doc.ents:\n",
    "            entity_text = ent.text\n",
    "            entity_type = str(ent.label_)\n",
    "            current_ents = {}\n",
    "\n",
    "            if entity_type in named_entities.keys():\n",
    "                current_ents = named_entities.get(entity_type)\n",
    "\n",
    "            current_ents[entity_text] = current_ents.get(entity_text, 0) + 1\n",
    "\n",
    "            named_entities[entity_type] = current_ents\n",
    "\n",
    "    return named_entities, processed_docs\n",
    "\n",
    "named_entities, processed_docs = return_entities_and_processed_docs(content_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GPE': {'New York City-area': 1,\n",
       "  'New York': 3,\n",
       "  'France': 1,\n",
       "  'South Korea': 1,\n",
       "  'US': 5,\n",
       "  'California': 1,\n",
       "  'Washington': 2,\n",
       "  'Australia': 3,\n",
       "  'Italy': 1,\n",
       "  'Cisco': 1,\n",
       "  'China': 2,\n",
       "  'Japan': 1,\n",
       "  'Tokyo': 3,\n",
       "  'East Africa': 1,\n",
       "  'Germany': 1,\n",
       "  'Netflix': 2,\n",
       "  'Canada': 1,\n",
       "  'Spain': 1,\n",
       "  'Poland': 1,\n",
       "  'Citi': 1,\n",
       "  'Massachusetts': 1},\n",
       " 'ORG': {'CNBC': 3,\n",
       "  'Mnuchin': 2,\n",
       "  'Emirates Airline': 1,\n",
       "  'Fed': 4,\n",
       "  'Congress': 4,\n",
       "  'NY': 1,\n",
       "  'Trump': 3,\n",
       "  'National Guard': 1,\n",
       "  'Dow': 1,\n",
       "  'Securities and Exchange Commission': 1,\n",
       "  'NYSE': 1,\n",
       "  'IBM': 1,\n",
       "  'White House': 1,\n",
       "  'Goldman': 1,\n",
       "  'Boeing': 2,\n",
       "  'Airbus': 1,\n",
       "  \"WeWork board's\": 1,\n",
       "  'SoftBank': 2,\n",
       "  'JetBlue': 1,\n",
       "  'Fauci': 1,\n",
       "  'Treasury': 2,\n",
       "  'Shell': 1,\n",
       "  'YouTube': 1,\n",
       "  'Deere': 1,\n",
       "  'Amazon': 1,\n",
       "  'Apple & more': 1,\n",
       "  'Hasbro': 2,\n",
       "  'Nike': 1,\n",
       "  'OECD': 1,\n",
       "  'GOP': 1,\n",
       "  'H&M': 1,\n",
       "  \"El-Erian: 'Pockets\": 1,\n",
       "  'GE Aviation': 1,\n",
       "  'CVS Health': 1,\n",
       "  'N95': 1,\n",
       "  'Bank of America': 1,\n",
       "  'CFO': 1,\n",
       "  'COVID-19': 1},\n",
       " 'MONEY': {'$4 trillion': 1,\n",
       "  '$225 million': 1,\n",
       "  '$41 billion': 1,\n",
       "  '$5 billion': 1},\n",
       " 'DATE': {'March 25': 1,\n",
       "  'the quarter': 1,\n",
       "  '2008': 1,\n",
       "  'worst week': 1,\n",
       "  '1991': 1,\n",
       "  '2020': 2,\n",
       "  'Monday': 1,\n",
       "  'today': 2,\n",
       "  'This week': 1,\n",
       "  'April 7': 1,\n",
       "  '6 months': 1},\n",
       " 'CARDINAL': {'6': 1,\n",
       "  'One': 1,\n",
       "  'about 2020': 1,\n",
       "  'thousands': 1,\n",
       "  '15,168': 1,\n",
       "  '5,000': 1,\n",
       "  '5': 1,\n",
       "  '400': 1,\n",
       "  '350,000': 1,\n",
       "  '15,000': 1,\n",
       "  '3': 2,\n",
       "  'tens of thousands': 1,\n",
       "  '50,000': 1},\n",
       " 'PERSON': {'Cuomo': 1,\n",
       "  'Rand Paul': 1,\n",
       "  'Angela Merkel': 1,\n",
       "  'Suze Orman': 1,\n",
       "  'Abe': 1,\n",
       "  'Tim Cook': 1,\n",
       "  'Elon Musk': 1,\n",
       "  'Op-Ed': 1,\n",
       "  'Brian Goldner': 1,\n",
       "  'Kelly Evans': 1,\n",
       "  'Steven Mnuchin': 1,\n",
       "  'Pat Toomey': 1,\n",
       "  'Richard LeFrak': 1,\n",
       "  'Ken Langone': 1,\n",
       "  'Mike Roman': 1,\n",
       "  'Ben McAdams': 1,\n",
       "  'Baker': 1,\n",
       "  'Harvey Weinstein': 1,\n",
       "  'Andrew Cuomo': 1},\n",
       " 'PERCENT': {'4%': 1,\n",
       "  'as much as 8%': 1,\n",
       "  'nearly 8%': 1,\n",
       "  'at least 10% to 15%': 1,\n",
       "  '10%': 1,\n",
       "  '30%': 1},\n",
       " 'LOC': {'Silicon Valley': 1, 'Europe': 3},\n",
       " 'EVENT': {'Olympics': 2, 'the Great Depression': 1},\n",
       " 'NORP': {'European': 2},\n",
       " 'TIME': {'noon': 1}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "named_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPE\n",
      " US: 5\n",
      " New York: 3\n",
      " Australia: 3\n",
      " Tokyo: 3\n",
      " Washington: 2\n",
      " China: 2\n",
      " Netflix: 2\n",
      "ORG\n",
      " Fed: 4\n",
      " Congress: 4\n",
      " CNBC: 3\n",
      " Trump: 3\n",
      " Mnuchin: 2\n",
      " Boeing: 2\n",
      " SoftBank: 2\n",
      " Treasury: 2\n",
      " Hasbro: 2\n",
      "MONEY\n",
      "DATE\n",
      " 2020: 2\n",
      " today: 2\n",
      "CARDINAL\n",
      " 3: 2\n",
      "PERSON\n",
      "PERCENT\n",
      "LOC\n",
      " Europe: 3\n",
      "EVENT\n",
      " Olympics: 2\n",
      "NORP\n",
      " European: 2\n",
      "TIME\n"
     ]
    }
   ],
   "source": [
    "def print_top_10(named_entities):\n",
    "    for key in named_entities.keys():\n",
    "        print(key)\n",
    "        entities = named_entities.get(key)\n",
    "\n",
    "        #Sort the entries by their frequency in descending\n",
    "        #Order and print out the most frequent n ones\n",
    "        sorted_keys = sorted(entities, key=entities.get, reverse=True)\n",
    "        for item in sorted_keys[:10]:\n",
    "            if (entities.get(item) > 1):\n",
    "                print(\" \" + item + \": \" + str(entities.get(item)))\n",
    "\n",
    "print_top_10(named_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['GPE', 'ORG', 'MONEY', 'DATE', 'CARDINAL', 'PERSON', 'PERCENT', 'LOC', 'EVENT', 'NORP', 'TIME'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "named_entities.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entity_span(document, entity):\n",
    "    indexes = []\n",
    "    for ent in document.ents:\n",
    "        if ent.text == entity:\n",
    "            for i in range(int(ent.start), int(ent.end)):\n",
    "                indexes.append(i)\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity = \"The New York City-area\"\n",
    "\n",
    "sentences = \"New York City-area airports halt air traffic as coronavirus causes staffing issues\"\n",
    "\n",
    "doc = nlp(sentences)\n",
    "\n",
    "calculate_entity_span(doc, entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT\n",
      "ROOT\n",
      "ROOT\n",
      "dep\n",
      "ROOT\n",
      "ROOT\n",
      "ROOT\n",
      "ROOT\n",
      "dep\n",
      "ROOT\n",
      "ROOT\n",
      "ROOT\n",
      "ROOT\n",
      "ROOT\n",
      "ROOT\n",
      "ROOT\n",
      "ROOT\n",
      "ROOT\n",
      "dep\n",
      "ROOT\n",
      "ROOT\n",
      "ROOT\n",
      "ROOT\n",
      "ROOT\n",
      "ROOT\n",
      "ROOT\n",
      "ROOT\n",
      "dep\n",
      "ROOT\n",
      "ROOT\n",
      "ROOT\n",
      "ROOT\n",
      "dep\n",
      "ROOT\n",
      "ROOT\n",
      "ROOT\n",
      "dep\n",
      "ROOT\n",
      "ROOT\n",
      "ROOT\n",
      "ROOT\n",
      "ROOT\n",
      "ROOT\n",
      "ROOT\n",
      "dep\n",
      "ROOT\n",
      "ROOT\n",
      "dep\n",
      "ROOT\n",
      "ROOT\n",
      "ROOT\n",
      "ROOT\n",
      "ROOT\n",
      "ROOT\n",
      "ROOT\n",
      "ROOT\n",
      "ROOT\n",
      "ROOT\n",
      "ROOT\n",
      "dep\n",
      "ROOT\n",
      "ROOT\n",
      "ROOT\n",
      "ROOT\n",
      "ROOT\n",
      "ROOT\n",
      "dep\n",
      "ROOT\n",
      "ROOT\n",
      "ROOT\n",
      "ROOT\n",
      "ROOT\n",
      "ROOT\n",
      "ROOT\n",
      "ROOT\n",
      "dep\n",
      "ROOT\n",
      "ROOT\n",
      "ROOT\n",
      "ROOT\n",
      "ROOT\n",
      "ROOT\n"
     ]
    }
   ],
   "source": [
    "for sentences in sentences:\n",
    "    doc = nlp(sentences)\n",
    "    for token in doc:\n",
    "        print(token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_entity_subject_object(document, entity, indexes):\n",
    "    actions = []\n",
    "    action = ''\n",
    "    participant1 = ''\n",
    "    participant2 = ''\n",
    "\n",
    "    for token in document:\n",
    "        #Next, you identify the main verb expressing the main action in the sentence\n",
    "        #To extract the relation, we have to find the ROOT of the sentence (which is also the verb of the sentence)\n",
    "        if token.pos == \"VERB\" and token.dep_ == 'ROOT':\n",
    "            #initialize the indexes for thesubject and the object related to the main verb\n",
    "            subj_ind = -1\n",
    "            obj_ind = -1\n",
    "            #store the main verb itself (token.text in the action variable)\n",
    "            action = token.text\n",
    "            children = [child for child in token.children]\n",
    "            for child1 in children:\n",
    "                #find the subject via the nsubj relation and store it as a participant1\n",
    "                #and its index as subj_ind\n",
    "                if child1.dep_ == 'nsubj':\n",
    "                    participant1 = child1.text\n",
    "                    sub_ind = int(child1.i)\n",
    "                #If there is a preposition attached to the verb (e.g.. \"write about\"), then\n",
    "                #you need to search for the indirect object as the second participant.\n",
    "                if child1.dep_ == 'prep':\n",
    "                    participant2 = ''\n",
    "                    child1_children = [child for child in child1.children]\n",
    "                    for child2 in child1_children:\n",
    "                        #If such an object is a noun or a proper noun\n",
    "                        #You store it as participant and its index as obj_ind\n",
    "                        if child2.pos_ == 'NOUN' or child2.pos_ == 'PROPN':\n",
    "                            participant2 = child2.text\n",
    "                            obj_ind = int(child2.i)\n",
    "\n",
    "                    #If at this point both participants of the main action have been identified and\n",
    "                    #their indexes are included in the indexes of the words covered by the entity,\n",
    "                    #you add the action with two participants to the list of actions\n",
    "                    if not participant2 == '':\n",
    "                        if subj_ind in indexes:\n",
    "                            actions.append(entity + \" \" + action + \" \", child1.text + \" \" + participant2)\n",
    "                        elif obj_ind in indexes:\n",
    "                            actions.append(participant1 + \" \" + actions + ' ' + child1.text + \" \" + entity)\n",
    "                #Otherwise, if there is no preposition attached to the verb,\n",
    "                #participant2 is a direct object of the main verb,\n",
    "                # which can be identified via the dobj relation\n",
    "                if child1.dep_ == 'dobj' == (child1.pos_ == 'NOUN' or child1.pos_ == 'PROPN'):\n",
    "                    participant2 = child1.text\n",
    "                    obj_ind = int(child1.i)\n",
    "                    # In this case you apply the same strategy as above,\n",
    "                    #adding the action with two participants to the list of actions.\n",
    "                    if subj_ind in indexes:\n",
    "                            actions.append(entity + \" \" + action + \" \", child1.text + \" \" + participant2)\n",
    "                    elif obj_ind in indexes:\n",
    "                            actions.append(participant1 + \" \" + action + \" \" + entity)\n",
    "    # FInally if the final list of actions is not empty,\n",
    "    # Print out the sentence and all actions together with the participants\n",
    "    if not len(actions) == 0:\n",
    "         print(f\"\\nSentence = {document}\")\n",
    "         for item in actions:\n",
    "              print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's check that it's working\n",
    "for sentence in sentences:\n",
    "    doc = nlp(sentence)\n",
    "    indexes = calculate_entity_span(doc, entity)\n",
    "    calc_entity_subject_object(doc, entity, indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trump activates National Guard in California, New York and Washington state to fight coronavirus outbreak, In coronavirus tweet storm, Trump touts suspect 'cure' and potential easing of guidelines to boost economy, Uber CEO asks Trump to support gig workers impacted by the coronavirus]\n"
     ]
    }
   ],
   "source": [
    "def return_docs_of_given_ent_type(processed_docs, entity, ent_type):\n",
    "    output_sentences = []\n",
    "    for doc in processed_docs:\n",
    "        for sentence in doc.sents:\n",
    "            # Only consider sentences that contain the input entity\n",
    "            # of the specified type among it's named entities\n",
    "            if entity in [ent.text for ent in sentence.ents if ent.label_ == ent_type]:\n",
    "               output_sentences.append(sentence)\n",
    "    return output_sentences\n",
    "entity = \"Trump\"\n",
    "\n",
    "ent_sentences = return_docs_of_given_ent_type(processed_docs, entity, 'ORG')\n",
    "print(ent_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in ent_sentences:\n",
    "    indexes = calculate_entity_span(sentence, entity)\n",
    "    calc_entity_subject_object(sentence, entity, indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Airlines tell Congress they need cash coronavirus aid or thousands will be furloughed, Congress struggles to reach a deal on its massive coronavirus stimulus bill, Stock market live updates: Dow futures down 400, waiting on Congress, 'limit down' again, Mnuchin says Congress is 'very close' to a stimulus agreement and must get it done 'today']\n"
     ]
    }
   ],
   "source": [
    "entity = \"Congress\"\n",
    "\n",
    "ent_sentences = return_docs_of_given_ent_type(processed_docs, entity, 'ORG')\n",
    "print(ent_sentences)\n",
    "\n",
    "for sentence in ent_sentences:\n",
    "    indexes = calculate_entity_span(sentence, entity)\n",
    "    calc_entity_subject_object(sentence, entity, indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Mr \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Kelvin\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " is a very Great man with Absolute personality alongside his dedication for the Apple Firm, and he currently resides in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Canada\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " .</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Performing named entity recognition on a random text\n",
    "from spacy import displacy\n",
    "\n",
    "text = 'Mr Kelvin is a very Great man with Absolute personality alongside his dedication for the Apple Firm, and he currently resides in Canada .'\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize entity types in sentences containing the specified entity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Trump\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " activates \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    National Guard\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    California\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    New York\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Washington\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " state to fight coronavirus outbreak</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">In coronavirus tweet storm, \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Trump\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " touts suspect 'cure' and potential easing of guidelines to boost economy</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Uber CEO asks \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Trump\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " to support gig workers impacted by the coronavirus</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_given_ent_type(processed_docs, entity, ent_type):\n",
    "    for doc in processed_docs:\n",
    "        for sentence in doc.sents:\n",
    "            if entity in [ent.text for ent in sentence.ents if ent.label_ == ent_type]:\n",
    "                displacy.render(sentence, style='ent')\n",
    "\n",
    "visualize_given_ent_type(processed_docs, 'Trump', 'ORG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let's find sentences where the particular named entity is used alongside other entities of the same type - i.e a specific\n",
    "# entity type is used in a particular number of times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def return_count_of_ent_type(sentence, ent_type):\n",
    "    return len([ent.text for ent in sentence.ents if ent.label_ == ent_type])\n",
    "\n",
    "text = 'Last week, Democratic lawmakers from both parties said they had the Senate votes needed to pass legislation that would prevent tech platforms, including Apple, GM and Facebook, from favouring their own businesses.'\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "return_count_of_ent_type(doc, 'ORG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "def return_docs_of_given_ent_type_custom(processed_docs, entity, ent_type):\n",
    "    output_sentences = []\n",
    "    for doc in processed_docs:\n",
    "        for sentence in doc.sents:\n",
    "            if entity in [ent.text for ent in sentence.ents if ent.label_ == ent_type and\n",
    "                          return_count_of_ent_type(sentence, ent_type) > 1 ]:\n",
    "                output_sentences.append(sentence)\n",
    "    return output_sentences\n",
    "\n",
    "output_sentences = return_docs_of_given_ent_type_custom(processed_docs, \"Trump\", \"ORG\")\n",
    "\n",
    "print(len(output_sentences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #64B5F6, #E0F7FA); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mnuchin\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " says \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #64B5F6, #E0F7FA); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Congress\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is 'very close' to a stimulus agreement and must get it done 'today'</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_conditional_sentences(sentences):\n",
    "    colors = {\"ORG\": \"linear-gradient(90deg, #64B5F6, #E0F7FA)\"}\n",
    "    options = {\"ents\": [\"ORG\"], \"colors\": colors}\n",
    "\n",
    "    for sentence in sentences:\n",
    "        displacy.render(sentence, style='ent', options=options)\n",
    "\n",
    "visualize_conditional_sentences(output_sentences)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
